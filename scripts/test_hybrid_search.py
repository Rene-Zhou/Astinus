#!/usr/bin/env python3
"""
æ··åˆæ£€ç´¢åŠŸèƒ½æµ‹è¯•è„šæœ¬

æµ‹è¯• Lore Agent çš„æ··åˆæ£€ç´¢åŠŸèƒ½ï¼ˆå…³é”®è¯ + å‘é‡ç›¸ä¼¼åº¦ï¼‰ï¼š
1. åˆå§‹åŒ–å‘é‡å­˜å‚¨å’Œ Lore Agent
2. åŠ è½½ demo_pack.json ä¸–ç•ŒåŒ…
3. æµ‹è¯•ä¸­è‹±æ–‡æ··åˆæŸ¥è¯¢
4. æ˜¾ç¤ºè¯¦ç»†çš„è¯„åˆ†å’Œæ’åä¿¡æ¯
5. éªŒè¯å…³é”®è¯ä¼˜å…ˆçº§å’Œè¯­ä¹‰ç†è§£çš„ç»“åˆæ•ˆæœ

ä½¿ç”¨æ–¹æ³•:
    python scripts/test_hybrid_search.py
"""

import asyncio
import sys
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ° Python è·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from src.backend.agents.lore import (
    KEYWORD_MATCH_WEIGHT,
    KEYWORD_SECONDARY_WEIGHT,
    VECTOR_MATCH_WEIGHT,
    DUAL_MATCH_BOOST,
    LoreAgent,
)
from src.backend.models.world_pack import WorldPack
from src.backend.services.vector_store import VectorStoreService
from src.backend.services.world import WorldPackLoader


def print_header(title: str) -> None:
    """æ‰“å°æ ¼å¼åŒ–çš„æ ‡é¢˜"""
    print(f"\n{'=' * 60}")
    print(f"  {title}")
    print(f"{'=' * 60}\n")


def print_success(message: str) -> None:
    """æ‰“å°æˆåŠŸæ¶ˆæ¯"""
    print(f"âœ… {message}")


def print_info(message: str) -> None:
    """æ‰“å°ä¿¡æ¯æ¶ˆæ¯"""
    print(f"â„¹ï¸  {message}")


def print_error(message: str) -> None:
    """æ‰“å°é”™è¯¯æ¶ˆæ¯"""
    print(f"âŒ {message}")


def print_divider() -> None:
    """æ‰“å°åˆ†éš”çº¿"""
    print("-" * 60)


def print_hybrid_result(
    query: str,
    lore_entries: list,
    world_pack,
    show_details: bool = True,
) -> None:
    """
    æ‰“å°æ··åˆæ£€ç´¢ç»“æœï¼Œæ˜¾ç¤ºè¯¦ç»†çš„è¯„åˆ†ä¿¡æ¯ã€‚

    Args:
        query: æŸ¥è¯¢æ–‡æœ¬
        lore_entries: è¿”å›çš„ lore æ¡ç›®åˆ—è¡¨
        world_pack: ä¸–ç•ŒåŒ…å®ä¾‹
        show_details: æ˜¯å¦æ˜¾ç¤ºè¯¦ç»†ä¿¡æ¯
    """
    print(f"\nğŸ” æŸ¥è¯¢: '{query}'")

    if not lore_entries:
        print("   æ²¡æœ‰æ‰¾åˆ°ç»“æœ")
        return

    print(f"   æ‰¾åˆ° {len(lore_entries)} æ¡ç»“æœ\n")

    # æ˜¾ç¤ºæ¯æ¡ç»“æœçš„è¯¦ç»†ä¿¡æ¯
    for i, entry in enumerate(lore_entries, 1):
        print(f"   [{i}] UID: {entry.uid}")
        print(f"       æ ‡é¢˜: {entry.key[0] if entry.key else 'N/A'}")

        # æ˜¾ç¤ºå†…å®¹æ‘˜è¦
        content = entry.content.get("cn") or entry.content.get("en", "")
        preview = content[:80] + "..." if len(content) > 80 else content
        print(f"       å†…å®¹: {preview}")

        # åˆ†æåŒ¹é…ç±»å‹
        is_primary_keyword_match = any(
            term in entry.key for term in _extract_search_terms(query)
        )
        has_secondary = hasattr(entry, "secondary_keys") and entry.secondary_keys
        is_secondary_keyword_match = has_secondary and any(
            term in entry.secondary_keys for term in _extract_search_terms(query)
        )

        match_type = []
        if is_primary_keyword_match:
            match_type.append(f"å…³é”®è¯(ä¸»è¦) æƒé‡:{KEYWORD_MATCH_WEIGHT}")
        elif is_secondary_keyword_match:
            match_type.append(f"å…³é”®è¯(æ¬¡è¦) æƒé‡:{KEYWORD_SECONDARY_WEIGHT}")
        else:
            match_type.append(f"è¯­ä¹‰ æƒé‡:{VECTOR_MATCH_WEIGHT}")

        print(f"       åŒ¹é…: {', '.join(match_type)}")
        print()


def _extract_search_terms(query: str) -> list[str]:
    """ç®€å•çš„å…³é”®è¯æå–ï¼ˆä¸ LoreAgent ä¸­çš„é€»è¾‘ä¸€è‡´ï¼‰"""
    import jieba

    stop_words = {
        "çš„", "äº†", "æ˜¯", "åœ¨", "æˆ‘", "ä½ ", "ä»–", "å¥¹", "å®ƒ", "æœ‰", "æ²¡æœ‰",
        "ä»€ä¹ˆ", "æ€ä¹ˆ", "å¦‚ä½•", "è¿™", "é‚£", "å°±", "ä¹Ÿ", "éƒ½", "å¾ˆ", "éå¸¸",
    }

    terms = []
    words = jieba.lcut(query)

    for word in words:
        clean_word = word.strip("ï¼Œã€‚ï¼ï¼Ÿï¼šï¼›''()ï¼ˆï¼‰[]ã€ã€‘\"\"")
        if (clean_word and
            clean_word not in stop_words and
            len(clean_word) > 1 and
            not clean_word.isspace()):
            terms.append(clean_word)

    # å»é‡å¹¶é™åˆ¶æ•°é‡
    seen = set()
    unique_terms = []
    for term in terms:
        if term not in seen:
            seen.add(term)
            unique_terms.append(term)
            if len(unique_terms) >= 5:
                break

    return unique_terms


async def test_hybrid_search(
    lore_agent,
    world_pack,
    queries: list[str],
    test_name: str,
) -> dict[str, any]:
    """
    æµ‹è¯•æ··åˆæ£€ç´¢å¹¶è¿”å›ç»Ÿè®¡ä¿¡æ¯ã€‚

    Args:
        lore_agent: Lore Agent å®ä¾‹
        world_pack: ä¸–ç•ŒåŒ…å®ä¾‹
        queries: æŸ¥è¯¢åˆ—è¡¨
        test_name: æµ‹è¯•åç§°

    Returns:
        ç»Ÿè®¡ä¿¡æ¯å­—å…¸
    """
    print_info(f"\n{test_name}")

    stats = {
        "total": 0,
        "keyword_match": 0,
        "semantic_match": 0,
        "correct_rankings": 0,
    }

    for query in queries:
        # ä½¿ç”¨ Lore Agent è¿›è¡Œæ··åˆæœç´¢
        result = await lore_agent.process({
            "query": query,
            "context": "æµ‹è¯•åœºæ™¯",
            "world_pack_id": "demo_pack",
        })

        if result.success:
            entries = []
            # ä»è¿”å›çš„å†…å®¹ä¸­æå–æ¡ç›®ï¼ˆè¿™é‡Œç®€åŒ–å¤„ç†ï¼Œå®é™…ä¼šä» metadata ä¸­è·å–ï¼‰
            # æˆ‘ä»¬éœ€è¦é‡æ–°è°ƒç”¨å†…éƒ¨æ–¹æ³•æ¥è·å–è¯¦ç»†ä¿¡æ¯
            entries = lore_agent._search_lore(
                world_pack, query, "æµ‹è¯•åœºæ™¯", None, None
            )

            stats["total"] += 1

            # åˆ†æç¬¬ä¸€æ¡ç»“æœçš„åŒ¹é…ç±»å‹
            if entries:
                first_entry = entries[0]

                # æ£€æŸ¥æ˜¯å¦æ˜¯å…³é”®è¯åŒ¹é…
                search_terms = _extract_search_terms(query)
                is_keyword_match = any(
                    term in first_entry.key for term in search_terms
                )

                if is_keyword_match:
                    stats["keyword_match"] += 1
                else:
                    stats["semantic_match"] += 1

            print_hybrid_result(query, entries, world_pack, show_details=True)
        else:
            print_error(f"æŸ¥è¯¢å¤±è´¥: {result.error}")

    return stats


async def main():
    """ä¸»æµ‹è¯•æµç¨‹"""
    print_header("Lore Agent æ··åˆæ£€ç´¢åŠŸèƒ½æµ‹è¯•")

    # æ˜¾ç¤ºå½“å‰é…ç½®
    print_info("æ··åˆæ£€ç´¢é…ç½®:")
    print(f"   - å…³é”®è¯åŒ¹é…æƒé‡ (ä¸»è¦): {KEYWORD_MATCH_WEIGHT}")
    print(f"   - å…³é”®è¯åŒ¹é…æƒé‡ (æ¬¡è¦): {KEYWORD_SECONDARY_WEIGHT}")
    print(f"   - å‘é‡ç›¸ä¼¼åº¦æƒé‡: {VECTOR_MATCH_WEIGHT}")
    print(f"   - åŒé‡åŒ¹é…åŠ æˆ: {DUAL_MATCH_BOOST}")

    # =========================================================================
    # 1. åˆå§‹åŒ–æœåŠ¡
    # =========================================================================
    print_info("\næ­¥éª¤ 1/4: åˆå§‹åŒ–å‘é‡å­˜å‚¨æœåŠ¡å’Œ Lore Agent")

    try:
        vector_db_path = project_root / "data" / "test_hybrid_search" / "chroma_db"
        vector_db_path.parent.mkdir(parents=True, exist_ok=True)

        # æ¸…ç†æ—§çš„æµ‹è¯•æ•°æ®
        if vector_db_path.exists():
            import shutil
            shutil.rmtree(vector_db_path)
            print_info("æ¸…ç†æ—§çš„æµ‹è¯•æ•°æ®")

        vector_store = VectorStoreService(db_path=vector_db_path)
        print_success("å‘é‡å­˜å‚¨æœåŠ¡å·²åˆå§‹åŒ–")
    except Exception as e:
        print_error(f"å‘é‡å­˜å‚¨åˆå§‹åŒ–å¤±è´¥: {e}")
        return 1

    # =========================================================================
    # 2. åŠ è½½ä¸–ç•ŒåŒ…å¹¶å»ºç«‹ç´¢å¼•
    # =========================================================================
    print_info("\næ­¥éª¤ 2/4: åŠ è½½ä¸–ç•ŒåŒ…å¹¶å»ºç«‹å‘é‡ç´¢å¼•")

    try:
        packs_dir = project_root / "data" / "packs"
        demo_pack_path = packs_dir / "demo_pack.json"

        if not demo_pack_path.exists():
            print_error(f"æœªæ‰¾åˆ° demo_pack.json: {demo_pack_path}")
            return 1

        # ä½¿ç”¨ WorldPackLoader åŠ è½½ï¼ˆå¯ç”¨å‘é‡ç´¢å¼•ï¼‰
        world_pack_loader = WorldPackLoader(
            packs_dir=packs_dir,
            vector_store=vector_store,
            enable_vector_indexing=True
        )

        world_pack = world_pack_loader.load("demo_pack")

        print_success(f"ä¸–ç•ŒåŒ…å·²åŠ è½½: {world_pack.info.name.cn}")
        print_info(f"  ç‰ˆæœ¬: {world_pack.info.version}")
        print_info(f"  Lore æ¡ç›®æ•°: {len(world_pack.entries)}")

        # ä¸ºæµ‹è¯•åˆ›å»ºä¸€ä¸ªç®€å•çš„ Lore Agentï¼ˆä¸éœ€è¦ LLMï¼‰
        from unittest.mock import MagicMock

        mock_llm = MagicMock()
        lore_agent = LoreAgent(
            llm=mock_llm,
            world_pack_loader=world_pack_loader,
            vector_store=vector_store
        )

        print_success("Lore Agent å·²åˆå§‹åŒ–")
    except Exception as e:
        print_error(f"åˆå§‹åŒ–å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return 1

    # =========================================================================
    # 3. æ‰§è¡Œä¸­æ–‡æŸ¥è¯¢æµ‹è¯•
    # =========================================================================
    print_info("\næ­¥éª¤ 3/4: æ‰§è¡Œä¸­æ–‡æŸ¥è¯¢æµ‹è¯•")

    chinese_queries = [
        ("åº„å›­çš„å†å²èƒŒæ™¯", 1),  # æœŸæœ›: UID 1 (å¹½æš—åº„å›­)
        ("ç®¡å®¶æ˜¯è°", 3),        # æœŸæœ›: UID 3 (ç®¡å®¶)
        ("å¯†å®¤é‡Œæœ‰ä»€ä¹ˆ", 2),    # æœŸæœ›: UID 2 (å¯†å®¤)
        ("ç«ç¾", 1),           # æœŸæœ›: UID 1 (åº„å›­) - åŒ…å«"ç«ç¾"
        ("é™ˆç²", None),        # NPC åå­—ï¼ŒæœŸæœ›æ— åŒ¹é…æˆ–è¯­ä¹‰ç›¸å…³
    ]

    cn_correct = 0
    cn_total = len(chinese_queries)

    for query, expected_uid in chinese_queries:
        entries = lore_agent._search_lore(
            world_pack, query, "æµ‹è¯•åœºæ™¯", None, None
        )

        print_divider()
        print_hybrid_result(query, entries, world_pack)

        if entries and expected_uid is not None:
            if entries[0].uid == expected_uid:
                cn_correct += 1
                print_success(f"   âœ… æ­£ç¡®åŒ¹é… UID {expected_uid}")
            else:
                print_error(f"   âŒ æœŸæœ› UID {expected_uid}ï¼Œå®é™… UID {entries[0].uid}")

    # =========================================================================
    # 4. æ‰§è¡Œè‹±æ–‡æŸ¥è¯¢æµ‹è¯•
    # =========================================================================
    print_info("\næ­¥éª¤ 4/4: æ‰§è¡Œè‹±æ–‡æŸ¥è¯¢æµ‹è¯•")

    english_queries = [
        ("manor history", 1),  # æœŸæœ›: UID 1 (å¹½æš—åº„å›­)
        ("butler", 3),         # æœŸæœ›: UID 3 (ç®¡å®¶)
        ("secret room", 2),    # æœŸæœ›: UID 2 (å¯†å®¤)
        ("fire incident", 1),  # æœŸæœ›: UID 1 æˆ– 3 (éƒ½åŒ…å« fire)
        ("Chen Ling", None),   # NPC åå­—ï¼ŒæœŸæœ›æ— åŒ¹é…æˆ–è¯­ä¹‰ç›¸å…³
    ]

    en_correct = 0
    en_total = len(english_queries)

    for query, expected_uid in english_queries:
        entries = lore_agent._search_lore(
            world_pack, query, "æµ‹è¯•åœºæ™¯", None, None
        )

        print_divider()
        print_hybrid_result(query, entries, world_pack)

        if entries and expected_uid is not None:
            if entries[0].uid == expected_uid:
                en_correct += 1
                print_success(f"   âœ… æ­£ç¡®åŒ¹é… UID {expected_uid}")
            else:
                print_error(f"   âŒ æœŸæœ› UID {expected_uid}ï¼Œå®é™… UID {entries[0].uid}")

    # =========================================================================
    # æ€»ç»“
    # =========================================================================
    print_header("æµ‹è¯•æ€»ç»“")

    total_queries = cn_total + en_total
    total_correct = cn_correct + en_correct
    accuracy = (total_correct / total_queries * 100) if total_queries > 0 else 0

    print(f"ä¸­æ–‡æŸ¥è¯¢å‡†ç¡®ç‡: {cn_correct}/{cn_total} ({cn_correct/cn_total*100:.1f}%)")
    print(f"è‹±æ–‡æŸ¥è¯¢å‡†ç¡®ç‡: {en_correct}/{en_total} ({en_correct/en_total*100:.1f}%)")
    print(f"æ€»ä½“å‡†ç¡®ç‡: {total_correct}/{total_queries} ({accuracy:.1f}%)")

    if accuracy >= 80:
        print_success("æ··åˆæ£€ç´¢æµ‹è¯•é€šè¿‡ï¼å‡†ç¡®ç‡ >= 80%")
    elif accuracy >= 60:
        print_info("æ··åˆæ£€ç´¢åŸºæœ¬å¯ç”¨ï¼Œå»ºè®®è¿›ä¸€æ­¥ä¼˜åŒ–")
    else:
        print_error("æ··åˆæ£€ç´¢éœ€è¦æ”¹è¿›")

    print_info(f"æµ‹è¯•æ•°æ®åº“ä½ç½®: {vector_db_path}")
    print_info("æç¤º: å¯ä»¥æ‰‹åŠ¨åˆ é™¤æµ‹è¯•æ•°æ®ç›®å½•")

    return 0


if __name__ == "__main__":
    sys.exit(asyncio.run(main()))
